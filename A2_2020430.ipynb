{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Grammar for MiniLang**\n"
      ],
      "metadata": {
        "id": "i6yFAx8fp8Ti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "program -> statement_list\n",
        "\n",
        "statement_list -> statement ';' statement_list | statement ';'\n",
        "statement -> assignment | conditional | print\n",
        "\n",
        "assignment -> IDENTIFIER '=' expression\n",
        "\n",
        "conditional -> 'if' '(' expression ')' '{' statement_list '}' 'else' '{' statement_list '}'\n",
        "\n",
        "print -> 'print' expression\n",
        "\n",
        "expression -> term | expression '+' term | expression '-' term\n",
        "term -> factor | term '*' factor | term '/' factor\n",
        "factor -> IDENTIFIER | INTEGER | '(' expression ')' | BOOLEAN | UNARY_OP factor\n",
        "\n",
        "UNARY_OP -> '!' | '-' | '+'\n",
        "\n",
        "BOOLEAN -> 'true' | 'false'\n"
      ],
      "metadata": {
        "id": "7tUHOEwMqIUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Top-down recursive descent parser for MiniLang**"
      ],
      "metadata": {
        "id": "fZO_eAOLqLSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Token types\n",
        "INTEGER = 'INTEGER'\n",
        "BOOLEAN = 'BOOLEAN'\n",
        "IDENTIFIER = 'IDENTIFIER'\n",
        "KEYWORD = 'KEYWORD'\n",
        "OPERATOR = 'OPERATOR'\n",
        "DELIMITER = 'DELIMITER'\n",
        "COMMENT = 'COMMENT'\n",
        "\n",
        "# Regular expressions for tokenization\n",
        "token_expressions = [\n",
        "    (r'\\d+', INTEGER),\n",
        "    (r'(true|false)', BOOLEAN),\n",
        "    (r'[a-zA-Z][a-zA-Z0-9_]*', IDENTIFIER),\n",
        "    (r'(if|else|print)', KEYWORD),\n",
        "    (r'[\\+\\-\\*\\/\\&\\|\\!\\=\\>\\<\\(\\)\\{\\}\\;\\=]', OPERATOR),\n",
        "    (r'\\/\\/.*', COMMENT),\n",
        "    (r'\\s+', None)  # Ignore whitespace\n",
        "]\n",
        "\n",
        "# Tokenize function\n",
        "def tokenize(code):\n",
        "    tokens = []\n",
        "    while code:\n",
        "        for pattern, token_type in token_expressions:\n",
        "            match = re.match(pattern, code)\n",
        "            if match:\n",
        "                value = match.group(0)\n",
        "                if token_type is not None:\n",
        "                    tokens.append((value, token_type))\n",
        "                break\n",
        "        code = code[len(value):]\n",
        "    return tokens\n",
        "\n",
        "# AST Node class\n",
        "class ASTNode:\n",
        "    def __init__(self, type_, value=None, children=None):\n",
        "        self.type = type_\n",
        "        self.value = value\n",
        "        self.children = children if children is not None else []\n",
        "\n",
        "    def __repr__(self):\n",
        "        if self.children:\n",
        "            return f'{self.type}({\", \".join(repr(child) for child in self.children)})'\n",
        "        elif self.value:\n",
        "            return f'{self.type}: {self.value}'\n",
        "        else:\n",
        "            return f'{self.type}'\n",
        "\n",
        "# Parser class\n",
        "class Parser:\n",
        "    def __init__(self, tokens):\n",
        "        self.tokens = tokens\n",
        "        self.current_token = None\n",
        "        self.token_index = -1\n",
        "        self.advance()\n",
        "\n",
        "    def advance(self):\n",
        "        self.token_index += 1\n",
        "        if self.token_index < len(self.tokens):\n",
        "            self.current_token = self.tokens[self.token_index]\n",
        "        else:\n",
        "            self.current_token = None\n",
        "\n",
        "    def parse(self):\n",
        "        return self.parse_program()\n",
        "\n",
        "    def parse_program(self):\n",
        "        program = ASTNode('Program')\n",
        "        while self.current_token:\n",
        "            statement = self.parse_statement()\n",
        "            if statement:\n",
        "                program.children.append(statement)\n",
        "        return program\n",
        "\n",
        "    def parse_statement(self):\n",
        "        token = self.current_token\n",
        "        if token[1] == KEYWORD:\n",
        "            if token[0] == 'if':\n",
        "                return self.parse_if_statement()\n",
        "            elif token[0] == 'print':\n",
        "                return self.parse_print_statement()\n",
        "        elif token[1] == IDENTIFIER:\n",
        "            return self.parse_assignment()\n",
        "        self.advance()  # Skip unsupported statement\n",
        "        return None\n",
        "\n",
        "    def parse_assignment(self):\n",
        "        identifier = self.current_token[0]\n",
        "        self.advance()  # Skip identifier\n",
        "        self.advance()  # Skip '='\n",
        "        value = self.parse_expression()\n",
        "        self.advance()  # Skip ';'\n",
        "        return ASTNode('Assignment', (identifier, value))\n",
        "\n",
        "    def parse_if_statement(self):\n",
        "        condition = self.parse_expression()\n",
        "        self.advance()  # Skip '{'\n",
        "        if_block = self.parse_program()\n",
        "        self.advance()  # Skip '}'\n",
        "        else_block = None\n",
        "        if self.current_token and self.current_token[0] == 'else':\n",
        "            self.advance()  # Skip 'else'\n",
        "            self.advance()  # Skip '{'\n",
        "            else_block = self.parse_program()\n",
        "            self.advance()  # Skip '}'\n",
        "        return ASTNode('IfStatement', (condition, if_block, else_block))\n",
        "\n",
        "    def parse_print_statement(self):\n",
        "        self.advance()  # Skip 'print'\n",
        "        value = self.parse_expression()\n",
        "        self.advance()  # Skip ';'\n",
        "        return ASTNode('PrintStatement', value)\n",
        "\n",
        "    def parse_expression(self):\n",
        "        # For simplicity, assuming expressions are only identifiers or literals\n",
        "        return ASTNode('Expression', self.current_token[0])\n",
        "\n",
        "# Main function to test the parser\n",
        "def main():\n",
        "    code = input(\"Enter MiniLang code: \")\n",
        "    tokens = tokenize(code)\n",
        "    parser = Parser(tokens)\n",
        "    ast = parser.parse()\n",
        "    print(ast)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2EAfcgGy49R",
        "outputId": "98214a7c-1285-4541-eb6c-545ea3710982"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter MiniLang code: z = x +;\n",
            "Program(Assignment: ('z', Expression: x))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ekmeb-7vdsvS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}